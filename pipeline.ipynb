{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import ClientSecretCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "from azure.mgmt.datafactory import DataFactoryManagementClient\n",
    "from azure.mgmt.datafactory import operations\n",
    "from azure.mgmt.datafactory.models import *\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_item(group):\n",
    "    \"\"\"Print an Azure object instance.\"\"\"\n",
    "    print(\"\\tName: {}\".format(group.name))\n",
    "    print(\"\\tId: {}\".format(group.id))\n",
    "    if hasattr(group, 'location'):\n",
    "        print(\"\\tLocation: {}\".format(group.location))\n",
    "    if hasattr(group, 'tags'):\n",
    "        print(\"\\tTags: {}\".format(group.tags))\n",
    "    if hasattr(group, 'properties'):\n",
    "        print_properties(group.properties)\n",
    "\n",
    "def print_properties(props):\n",
    "    \"\"\"Print a ResourceGroup properties instance.\"\"\"\n",
    "    if props and hasattr(props, 'provisioning_state') and props.provisioning_state:\n",
    "        print(\"\\tProperties:\")\n",
    "        print(\"\\t\\tProvisioning State: {}\".format(props.provisioning_state))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "def print_activity_run_details(activity_run):\n",
    "    \"\"\"Print activity run details.\"\"\"\n",
    "    print(\"\\n\\tActivity run details\\n\")\n",
    "    print(\"\\tActivity run status: {}\".format(activity_run.status))\n",
    "    if activity_run.status == 'Succeeded':\n",
    "        print(\"\\tNumber of bytes read: {}\".format(activity_run.output['dataRead']))\n",
    "        print(\"\\tNumber of bytes written: {}\".format(activity_run.output['dataWritten']))\n",
    "        print(\"\\tCopy duration: {}\".format(activity_run.output['copyDuration']))\n",
    "    else:\n",
    "        print(\"\\tErrors: {}\".format(activity_run.error['message']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uses an APP Client and Secret for authentication\n",
    "\n",
    "This can be used with a security principal or in the case below an App that has contributor role in ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "rg_name = 'ecolab-rg'\n",
    "df_name = 'ecolab-adf'\n",
    "\n",
    "def connect_to_adf():\n",
    "    subscription_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
    "\n",
    "    credentials = ClientSecretCredential(\n",
    "        client_id = 'a888b9fe-38ff-4551-844f-7416e1cbb89f',\n",
    "        client_secret=os.getenv(\"ECOLAB_ADF_SP_SECRET\"),\n",
    "        tenant_id=os.getenv(\"TENANT_ID\")\n",
    "    )\n",
    "    print(credentials)\n",
    "    #credentials = DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
    "\n",
    "    #resource_client = ResourceManagementClient(credentials, subscription_id)\n",
    "    adf_client = DataFactoryManagementClient(credentials, subscription_id)\n",
    "    return adf_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azure.identity._credentials.client_secret.ClientSecretCredential object at 0x7fa0c42fd700>\n"
     ]
    }
   ],
   "source": [
    "#adf_client.operations.list()\n",
    "#operations.PipelinesOperations.list_by_factory( resource_group_name=rg_name, factory_name=df_name )\n",
    "#o = operations\n",
    "\n",
    "adf_client = connect_to_adf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = adf_client.factories.create_or_update(rg_name, df_name, df_resource)\n",
    "for x in adf_client.factories.configure_factory_repo():\n",
    "    print(x)\n",
    "\n",
    "adf_client.factories.models.FactoryRepoUpdate()\n",
    "#adf_client.factories.configure_factory_repo(location_id= str, factory_repo_update=azure.mgmt.datafactory.models._models_py3.FactoryRepoUpdate, **kwargs: Any) -> azure.mgmt.datafactory.models._models_py3.Factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'inside'\n",
    "dsOut_name = 'outside'\n",
    "\n",
    "act_name = 'copyBlobtoBlob'\n",
    "blob_source = BlobSource()\n",
    "blob_sink = BlobSink()\n",
    "dsin_ref = DatasetReference(reference_name=ds_name)\n",
    "dsOut_ref = DatasetReference(reference_name=dsOut_name)\n",
    "copy_activity = CopyActivity(name=act_name,inputs=[dsin_ref], outputs=[dsOut_ref], source=blob_source, sink=blob_sink)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first-pipeline\n",
      " this is the retry value of the activity 1\n",
      " this is the timeout value of the activity 05:00\n",
      "this is the amount of seconds to wait between retry 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "adf_client.operations.models.FactoryRepoConfiguration(account_name=\"SupportedCustomers\",repository_name=\"ecolab\",collaboration_branch=\"test1\",root_folder=\"main\")\n",
    "\n",
    "for pipeline in adf_client.pipelines.list_by_factory(resource_group_name=rg_name, factory_name=df_name):\n",
    "    print(pipeline.name)\n",
    "\n",
    "    #pipe = adf_client.pipelines.create_or_update(resource_group_name=rg_name, factory_name=df_name, pipeline_name=pipeline.name, pipeline=pipeline)\n",
    "    #print(pipe)\n",
    "\n",
    "#    adf_client.operations.models.FactoryRepoUpdate\n",
    "\n",
    "    for p in pipeline.activities:\n",
    "        if str(type(p)).split(\".\")[-1].replace(\"'>\",\"\") == 'CopyActivity':\n",
    "            print(f' this is the retry value of the activity {p.policy.retry}')\n",
    "            print(f' this is the timeout value of the activity {p.policy.timeout}')\n",
    "            print(f'this is the amount of seconds to wait between retry {p.policy.retry_interval_in_seconds}')\n",
    "            p.policy.retry = 1\n",
    "            p.policy.timeout = \"05:00\"\n",
    "            p.policy.retry_interval_in_seconds = 100\n",
    "            \n",
    "            pipe_validation_errors = pipeline.validate()\n",
    "            for pve in pipe_validation_errors:\n",
    "                print(pve)\n",
    "\n",
    "\n",
    "            params_for_pipeline = {}                \n",
    "            p_obj = PipelineResource(activities=[p], parameters=params_for_pipeline)\n",
    "            adf_client.pipelines.create_or_update(resource_group_name=rg_name, factory_name=df_name, pipeline_name=pipeline.name, pipeline=p_obj)\n",
    "\n",
    "            \n",
    "    pipeline.validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in adf_client.datasets.list_by_factory(resource_group_name=rg_name, factory_name=df_name):\n",
    "    ds = adf_client.datasets.create_or_update(resource_group_name=rg_name, factory_name=df_name, dataset_name=dataset.name, dataset=dataset)\n",
    "\n",
    "    try:\n",
    "        ls = adf_client.linked_services.get(resource_group_name=rg_name, factory_name=df_name, linked_service_name=ds.properties.linked_service_name.reference_name)\n",
    "        \n",
    "        print(ls.properties.url)\n",
    "        ls.properties.url=\"https://www.cnn.com\"\n",
    "        #ls.properties.url=\"https://swapi.dev/api/people\"\n",
    "        ls.validate\n",
    "    \n",
    "        \n",
    "\n",
    "        adf_client.linked_services.create_or_update(resource_group_name=rg_name, factory_name=df_name, linked_service_name=ls.name, linked_service=ls)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_client.linked_services.create_or_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "425910ad7b0a9c243ce82a976fc25304132f307acf03a97642b6c5bd717ea908"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ecolab_adf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
